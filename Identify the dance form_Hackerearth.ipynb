{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/dataset/train.csv\n/kaggle/input/dataset/test.csv\n/kaggle/input/dataset/train/234.jpg\n/kaggle/input/dataset/train/287.jpg\n/kaggle/input/dataset/train/87.jpg\n/kaggle/input/dataset/train/404.jpg\n/kaggle/input/dataset/train/167.jpg\n/kaggle/input/dataset/train/257.jpg\n/kaggle/input/dataset/train/163.jpg\n/kaggle/input/dataset/train/148.jpg\n/kaggle/input/dataset/train/251.jpg\n/kaggle/input/dataset/train/184.jpg\n/kaggle/input/dataset/train/99.jpg\n/kaggle/input/dataset/train/433.jpg\n/kaggle/input/dataset/train/90.jpg\n/kaggle/input/dataset/train/475.jpg\n/kaggle/input/dataset/train/76.jpg\n/kaggle/input/dataset/train/468.jpg\n/kaggle/input/dataset/train/73.jpg\n/kaggle/input/dataset/train/501.jpg\n/kaggle/input/dataset/train/379.jpg\n/kaggle/input/dataset/train/310.jpg\n/kaggle/input/dataset/train/212.jpg\n/kaggle/input/dataset/train/418.jpg\n/kaggle/input/dataset/train/106.jpg\n/kaggle/input/dataset/train/428.jpg\n/kaggle/input/dataset/train/42.jpg\n/kaggle/input/dataset/train/111.jpg\n/kaggle/input/dataset/train/371.jpg\n/kaggle/input/dataset/train/142.jpg\n/kaggle/input/dataset/train/341.jpg\n/kaggle/input/dataset/train/49.jpg\n/kaggle/input/dataset/train/478.jpg\n/kaggle/input/dataset/train/319.jpg\n/kaggle/input/dataset/train/227.jpg\n/kaggle/input/dataset/train/236.jpg\n/kaggle/input/dataset/train/75.jpg\n/kaggle/input/dataset/train/512.jpg\n/kaggle/input/dataset/train/156.jpg\n/kaggle/input/dataset/train/502.jpg\n/kaggle/input/dataset/train/387.jpg\n/kaggle/input/dataset/train/140.jpg\n/kaggle/input/dataset/train/199.jpg\n/kaggle/input/dataset/train/26.jpg\n/kaggle/input/dataset/train/494.jpg\n/kaggle/input/dataset/train/122.jpg\n/kaggle/input/dataset/train/155.jpg\n/kaggle/input/dataset/train/415.jpg\n/kaggle/input/dataset/train/69.jpg\n/kaggle/input/dataset/train/197.jpg\n/kaggle/input/dataset/train/124.jpg\n/kaggle/input/dataset/train/436.jpg\n/kaggle/input/dataset/train/240.jpg\n/kaggle/input/dataset/train/434.jpg\n/kaggle/input/dataset/train/109.jpg\n/kaggle/input/dataset/train/515.jpg\n/kaggle/input/dataset/train/164.jpg\n/kaggle/input/dataset/train/351.jpg\n/kaggle/input/dataset/train/107.jpg\n/kaggle/input/dataset/train/263.jpg\n/kaggle/input/dataset/train/519.jpg\n/kaggle/input/dataset/train/427.jpg\n/kaggle/input/dataset/train/91.jpg\n/kaggle/input/dataset/train/370.jpg\n/kaggle/input/dataset/train/126.jpg\n/kaggle/input/dataset/train/135.jpg\n/kaggle/input/dataset/train/247.jpg\n/kaggle/input/dataset/train/325.jpg\n/kaggle/input/dataset/train/504.jpg\n/kaggle/input/dataset/train/83.jpg\n/kaggle/input/dataset/train/168.jpg\n/kaggle/input/dataset/train/230.jpg\n/kaggle/input/dataset/train/101.jpg\n/kaggle/input/dataset/train/397.jpg\n/kaggle/input/dataset/train/12.jpg\n/kaggle/input/dataset/train/213.jpg\n/kaggle/input/dataset/train/154.jpg\n/kaggle/input/dataset/train/185.jpg\n/kaggle/input/dataset/train/331.jpg\n/kaggle/input/dataset/train/445.jpg\n/kaggle/input/dataset/train/353.jpg\n/kaggle/input/dataset/train/393.jpg\n/kaggle/input/dataset/train/177.jpg\n/kaggle/input/dataset/train/115.jpg\n/kaggle/input/dataset/train/361.jpg\n/kaggle/input/dataset/train/451.jpg\n/kaggle/input/dataset/train/43.jpg\n/kaggle/input/dataset/train/2.jpg\n/kaggle/input/dataset/train/139.jpg\n/kaggle/input/dataset/train/496.jpg\n/kaggle/input/dataset/train/181.jpg\n/kaggle/input/dataset/train/85.jpg\n/kaggle/input/dataset/train/100.jpg\n/kaggle/input/dataset/train/24.jpg\n/kaggle/input/dataset/train/149.jpg\n/kaggle/input/dataset/train/144.jpg\n/kaggle/input/dataset/train/21.jpg\n/kaggle/input/dataset/train/231.jpg\n/kaggle/input/dataset/train/289.jpg\n/kaggle/input/dataset/train/499.jpg\n/kaggle/input/dataset/train/419.jpg\n/kaggle/input/dataset/train/312.jpg\n/kaggle/input/dataset/train/180.jpg\n/kaggle/input/dataset/train/481.jpg\n/kaggle/input/dataset/train/25.jpg\n/kaggle/input/dataset/train/355.jpg\n/kaggle/input/dataset/train/117.jpg\n/kaggle/input/dataset/train/395.jpg\n/kaggle/input/dataset/train/96.jpg\n/kaggle/input/dataset/train/364.jpg\n/kaggle/input/dataset/train/10.jpg\n/kaggle/input/dataset/train/53.jpg\n/kaggle/input/dataset/train/430.jpg\n/kaggle/input/dataset/train/153.jpg\n/kaggle/input/dataset/train/81.jpg\n/kaggle/input/dataset/train/79.jpg\n/kaggle/input/dataset/train/454.jpg\n/kaggle/input/dataset/train/381.jpg\n/kaggle/input/dataset/train/273.jpg\n/kaggle/input/dataset/train/262.jpg\n/kaggle/input/dataset/train/293.jpg\n/kaggle/input/dataset/train/261.jpg\n/kaggle/input/dataset/train/472.jpg\n/kaggle/input/dataset/train/211.jpg\n/kaggle/input/dataset/train/422.jpg\n/kaggle/input/dataset/train/296.jpg\n/kaggle/input/dataset/train/243.jpg\n/kaggle/input/dataset/train/492.jpg\n/kaggle/input/dataset/train/295.jpg\n/kaggle/input/dataset/train/425.jpg\n/kaggle/input/dataset/train/493.jpg\n/kaggle/input/dataset/train/336.jpg\n/kaggle/input/dataset/train/266.jpg\n/kaggle/input/dataset/train/413.jpg\n/kaggle/input/dataset/train/249.jpg\n/kaggle/input/dataset/train/320.jpg\n/kaggle/input/dataset/train/277.jpg\n/kaggle/input/dataset/train/367.jpg\n/kaggle/input/dataset/train/84.jpg\n/kaggle/input/dataset/train/420.jpg\n/kaggle/input/dataset/train/223.jpg\n/kaggle/input/dataset/train/176.jpg\n/kaggle/input/dataset/train/328.jpg\n/kaggle/input/dataset/train/30.jpg\n/kaggle/input/dataset/train/89.jpg\n/kaggle/input/dataset/train/121.jpg\n/kaggle/input/dataset/train/201.jpg\n/kaggle/input/dataset/train/337.jpg\n/kaggle/input/dataset/train/483.jpg\n/kaggle/input/dataset/train/267.jpg\n/kaggle/input/dataset/train/276.jpg\n/kaggle/input/dataset/train/443.jpg\n/kaggle/input/dataset/train/409.jpg\n/kaggle/input/dataset/train/288.jpg\n/kaggle/input/dataset/train/488.jpg\n/kaggle/input/dataset/train/359.jpg\n/kaggle/input/dataset/train/490.jpg\n/kaggle/input/dataset/train/229.jpg\n/kaggle/input/dataset/train/82.jpg\n/kaggle/input/dataset/train/195.jpg\n/kaggle/input/dataset/train/134.jpg\n/kaggle/input/dataset/train/432.jpg\n/kaggle/input/dataset/train/219.jpg\n/kaggle/input/dataset/train/372.jpg\n/kaggle/input/dataset/train/130.jpg\n/kaggle/input/dataset/train/233.jpg\n/kaggle/input/dataset/train/388.jpg\n/kaggle/input/dataset/train/178.jpg\n/kaggle/input/dataset/train/174.jpg\n/kaggle/input/dataset/train/72.jpg\n/kaggle/input/dataset/train/426.jpg\n/kaggle/input/dataset/train/376.jpg\n/kaggle/input/dataset/train/18.jpg\n/kaggle/input/dataset/train/477.jpg\n/kaggle/input/dataset/train/172.jpg\n/kaggle/input/dataset/train/486.jpg\n/kaggle/input/dataset/train/207.jpg\n/kaggle/input/dataset/train/228.jpg\n/kaggle/input/dataset/train/50.jpg\n/kaggle/input/dataset/train/327.jpg\n/kaggle/input/dataset/train/282.jpg\n/kaggle/input/dataset/train/169.jpg\n/kaggle/input/dataset/train/352.jpg\n/kaggle/input/dataset/train/382.jpg\n/kaggle/input/dataset/train/339.jpg\n/kaggle/input/dataset/train/459.jpg\n/kaggle/input/dataset/train/491.jpg\n/kaggle/input/dataset/train/102.jpg\n/kaggle/input/dataset/train/105.jpg\n/kaggle/input/dataset/train/222.jpg\n/kaggle/input/dataset/train/400.jpg\n/kaggle/input/dataset/train/56.jpg\n/kaggle/input/dataset/train/511.jpg\n/kaggle/input/dataset/train/205.jpg\n/kaggle/input/dataset/train/500.jpg\n/kaggle/input/dataset/train/208.jpg\n/kaggle/input/dataset/train/450.jpg\n/kaggle/input/dataset/train/304.jpg\n/kaggle/input/dataset/train/54.jpg\n/kaggle/input/dataset/train/348.jpg\n/kaggle/input/dataset/train/383.jpg\n/kaggle/input/dataset/train/452.jpg\n/kaggle/input/dataset/train/357.jpg\n/kaggle/input/dataset/train/22.jpg\n/kaggle/input/dataset/train/369.jpg\n/kaggle/input/dataset/train/389.jpg\n/kaggle/input/dataset/train/158.jpg\n/kaggle/input/dataset/train/449.jpg\n/kaggle/input/dataset/train/1.jpg\n/kaggle/input/dataset/train/342.jpg\n/kaggle/input/dataset/train/453.jpg\n/kaggle/input/dataset/train/347.jpg\n/kaggle/input/dataset/train/131.jpg\n/kaggle/input/dataset/train/159.jpg\n/kaggle/input/dataset/train/258.jpg\n/kaggle/input/dataset/train/377.jpg\n/kaggle/input/dataset/train/252.jpg\n/kaggle/input/dataset/train/15.jpg\n/kaggle/input/dataset/train/63.jpg\n/kaggle/input/dataset/train/412.jpg\n/kaggle/input/dataset/train/58.jpg\n/kaggle/input/dataset/train/77.jpg\n/kaggle/input/dataset/train/242.jpg\n/kaggle/input/dataset/train/455.jpg\n/kaggle/input/dataset/train/29.jpg\n/kaggle/input/dataset/train/161.jpg\n/kaggle/input/dataset/train/350.jpg\n/kaggle/input/dataset/train/435.jpg\n/kaggle/input/dataset/train/321.jpg\n/kaggle/input/dataset/train/225.jpg\n/kaggle/input/dataset/train/462.jpg\n/kaggle/input/dataset/train/403.jpg\n/kaggle/input/dataset/train/88.jpg\n/kaggle/input/dataset/train/503.jpg\n/kaggle/input/dataset/train/190.jpg\n/kaggle/input/dataset/train/136.jpg\n/kaggle/input/dataset/train/78.jpg\n/kaggle/input/dataset/train/137.jpg\n/kaggle/input/dataset/train/417.jpg\n/kaggle/input/dataset/train/188.jpg\n/kaggle/input/dataset/train/68.jpg\n/kaggle/input/dataset/train/489.jpg\n/kaggle/input/dataset/train/311.jpg\n/kaggle/input/dataset/train/260.jpg\n/kaggle/input/dataset/train/309.jpg\n/kaggle/input/dataset/train/471.jpg\n/kaggle/input/dataset/train/307.jpg\n/kaggle/input/dataset/train/343.jpg\n/kaggle/input/dataset/train/179.jpg\n/kaggle/input/dataset/train/143.jpg\n/kaggle/input/dataset/train/51.jpg\n/kaggle/input/dataset/train/315.jpg\n/kaggle/input/dataset/train/407.jpg\n/kaggle/input/dataset/train/203.jpg\n/kaggle/input/dataset/train/70.jpg\n/kaggle/input/dataset/train/446.jpg\n/kaggle/input/dataset/train/265.jpg\n/kaggle/input/dataset/train/298.jpg\n/kaggle/input/dataset/train/44.jpg\n/kaggle/input/dataset/train/151.jpg\n/kaggle/input/dataset/train/191.jpg\n/kaggle/input/dataset/train/272.jpg\n/kaggle/input/dataset/train/104.jpg\n/kaggle/input/dataset/train/464.jpg\n/kaggle/input/dataset/train/253.jpg\n/kaggle/input/dataset/train/46.jpg\n/kaggle/input/dataset/train/476.jpg\n/kaggle/input/dataset/train/362.jpg\n/kaggle/input/dataset/train/133.jpg\n/kaggle/input/dataset/train/165.jpg\n/kaggle/input/dataset/train/308.jpg\n/kaggle/input/dataset/train/444.jpg\n/kaggle/input/dataset/train/31.jpg\n/kaggle/input/dataset/train/396.jpg\n/kaggle/input/dataset/train/94.jpg\n/kaggle/input/dataset/train/405.jpg\n/kaggle/input/dataset/train/3.jpg\n/kaggle/input/dataset/train/294.jpg\n/kaggle/input/dataset/train/160.jpg\n/kaggle/input/dataset/train/255.jpg\n/kaggle/input/dataset/train/248.jpg\n/kaggle/input/dataset/train/345.jpg\n/kaggle/input/dataset/train/37.jpg\n/kaggle/input/dataset/train/250.jpg\n/kaggle/input/dataset/train/254.jpg\n/kaggle/input/dataset/train/402.jpg\n/kaggle/input/dataset/train/305.jpg\n/kaggle/input/dataset/train/103.jpg\n/kaggle/input/dataset/train/469.jpg\n/kaggle/input/dataset/train/8.jpg\n/kaggle/input/dataset/train/408.jpg\n/kaggle/input/dataset/train/497.jpg\n/kaggle/input/dataset/train/244.jpg\n/kaggle/input/dataset/train/241.jpg\n/kaggle/input/dataset/train/123.jpg\n/kaggle/input/dataset/train/513.jpg\n/kaggle/input/dataset/train/259.jpg\n/kaggle/input/dataset/train/65.jpg\n/kaggle/input/dataset/train/113.jpg\n/kaggle/input/dataset/train/365.jpg\n/kaggle/input/dataset/train/186.jpg\n/kaggle/input/dataset/train/221.jpg\n/kaggle/input/dataset/train/344.jpg\n/kaggle/input/dataset/train/218.jpg\n/kaggle/input/dataset/train/98.jpg\n/kaggle/input/dataset/train/118.jpg\n/kaggle/input/dataset/train/399.jpg\n/kaggle/input/dataset/train/7.jpg\n/kaggle/input/dataset/train/281.jpg\n/kaggle/input/dataset/train/303.jpg\n/kaggle/input/dataset/train/245.jpg\n/kaggle/input/dataset/train/214.jpg\n/kaggle/input/dataset/train/187.jpg\n/kaggle/input/dataset/train/423.jpg\n/kaggle/input/dataset/train/60.jpg\n/kaggle/input/dataset/train/335.jpg\n/kaggle/input/dataset/train/384.jpg\n/kaggle/input/dataset/train/297.jpg\n/kaggle/input/dataset/train/66.jpg\n/kaggle/input/dataset/train/4.jpg\n/kaggle/input/dataset/train/338.jpg\n/kaggle/input/dataset/train/368.jpg\n/kaggle/input/dataset/train/47.jpg\n/kaggle/input/dataset/train/268.jpg\n/kaggle/input/dataset/train/334.jpg\n/kaggle/input/dataset/train/204.jpg\n/kaggle/input/dataset/train/326.jpg\n/kaggle/input/dataset/train/19.jpg\n/kaggle/input/dataset/train/120.jpg\n/kaggle/input/dataset/train/93.jpg\n/kaggle/input/dataset/train/62.jpg\n/kaggle/input/dataset/train/237.jpg\n/kaggle/input/dataset/train/141.jpg\n/kaggle/input/dataset/train/235.jpg\n/kaggle/input/dataset/train/5.jpg\n/kaggle/input/dataset/train/442.jpg\n/kaggle/input/dataset/train/322.jpg\n/kaggle/input/dataset/train/333.jpg\n/kaggle/input/dataset/train/116.jpg\n/kaggle/input/dataset/train/16.jpg\n/kaggle/input/dataset/train/391.jpg\n/kaggle/input/dataset/train/299.jpg\n/kaggle/input/dataset/train/192.jpg\n/kaggle/input/dataset/train/406.jpg\n/kaggle/input/dataset/train/52.jpg\n/kaggle/input/dataset/train/329.jpg\n/kaggle/input/dataset/train/182.jpg\n/kaggle/input/dataset/train/516.jpg\n/kaggle/input/dataset/train/466.jpg\n/kaggle/input/dataset/train/474.jpg\n/kaggle/input/dataset/train/27.jpg\n/kaggle/input/dataset/train/166.jpg\n/kaggle/input/dataset/train/209.jpg\n/kaggle/input/dataset/train/356.jpg\n/kaggle/input/dataset/train/300.jpg\n/kaggle/input/dataset/train/480.jpg\n/kaggle/input/dataset/train/274.jpg\n/kaggle/input/dataset/train/279.jpg\n/kaggle/input/dataset/train/39.jpg\n/kaggle/input/dataset/train/74.jpg\n/kaggle/input/dataset/train/32.jpg\n/kaggle/input/dataset/train/36.jpg\n/kaggle/input/dataset/train/314.jpg\n/kaggle/input/dataset/train/313.jpg\n/kaggle/input/dataset/train/509.jpg\n/kaggle/input/dataset/train/127.jpg\n/kaggle/input/dataset/test/170.jpg\n/kaggle/input/dataset/test/438.jpg\n/kaggle/input/dataset/test/458.jpg\n/kaggle/input/dataset/test/510.jpg\n/kaggle/input/dataset/test/138.jpg\n/kaggle/input/dataset/test/238.jpg\n/kaggle/input/dataset/test/38.jpg\n/kaggle/input/dataset/test/479.jpg\n/kaggle/input/dataset/test/264.jpg\n/kaggle/input/dataset/test/278.jpg\n/kaggle/input/dataset/test/424.jpg\n/kaggle/input/dataset/test/97.jpg\n/kaggle/input/dataset/test/506.jpg\n/kaggle/input/dataset/test/441.jpg\n/kaggle/input/dataset/test/48.jpg\n/kaggle/input/dataset/test/390.jpg\n/kaggle/input/dataset/test/64.jpg\n/kaggle/input/dataset/test/112.jpg\n/kaggle/input/dataset/test/485.jpg\n/kaggle/input/dataset/test/414.jpg\n/kaggle/input/dataset/test/495.jpg\n/kaggle/input/dataset/test/292.jpg\n/kaggle/input/dataset/test/183.jpg\n/kaggle/input/dataset/test/463.jpg\n/kaggle/input/dataset/test/13.jpg\n/kaggle/input/dataset/test/461.jpg\n/kaggle/input/dataset/test/146.jpg\n/kaggle/input/dataset/test/132.jpg\n/kaggle/input/dataset/test/392.jpg\n/kaggle/input/dataset/test/217.jpg\n/kaggle/input/dataset/test/71.jpg\n/kaggle/input/dataset/test/324.jpg\n/kaggle/input/dataset/test/346.jpg\n/kaggle/input/dataset/test/150.jpg\n/kaggle/input/dataset/test/216.jpg\n/kaggle/input/dataset/test/206.jpg\n/kaggle/input/dataset/test/59.jpg\n/kaggle/input/dataset/test/110.jpg\n/kaggle/input/dataset/test/92.jpg\n/kaggle/input/dataset/test/33.jpg\n/kaggle/input/dataset/test/196.jpg\n/kaggle/input/dataset/test/128.jpg\n/kaggle/input/dataset/test/447.jpg\n/kaggle/input/dataset/test/175.jpg\n/kaggle/input/dataset/test/518.jpg\n/kaggle/input/dataset/test/286.jpg\n/kaggle/input/dataset/test/95.jpg\n/kaggle/input/dataset/test/198.jpg\n/kaggle/input/dataset/test/401.jpg\n/kaggle/input/dataset/test/61.jpg\n/kaggle/input/dataset/test/507.jpg\n/kaggle/input/dataset/test/340.jpg\n/kaggle/input/dataset/test/239.jpg\n/kaggle/input/dataset/test/125.jpg\n/kaggle/input/dataset/test/246.jpg\n/kaggle/input/dataset/test/514.jpg\n/kaggle/input/dataset/test/129.jpg\n/kaggle/input/dataset/test/271.jpg\n/kaggle/input/dataset/test/374.jpg\n/kaggle/input/dataset/test/283.jpg\n/kaggle/input/dataset/test/40.jpg\n/kaggle/input/dataset/test/162.jpg\n/kaggle/input/dataset/test/517.jpg\n/kaggle/input/dataset/test/275.jpg\n/kaggle/input/dataset/test/67.jpg\n/kaggle/input/dataset/test/284.jpg\n/kaggle/input/dataset/test/366.jpg\n/kaggle/input/dataset/test/465.jpg\n/kaggle/input/dataset/test/318.jpg\n/kaggle/input/dataset/test/226.jpg\n/kaggle/input/dataset/test/360.jpg\n/kaggle/input/dataset/test/429.jpg\n/kaggle/input/dataset/test/108.jpg\n/kaggle/input/dataset/test/317.jpg\n/kaggle/input/dataset/test/9.jpg\n/kaggle/input/dataset/test/354.jpg\n/kaggle/input/dataset/test/290.jpg\n/kaggle/input/dataset/test/34.jpg\n/kaggle/input/dataset/test/358.jpg\n/kaggle/input/dataset/test/147.jpg\n/kaggle/input/dataset/test/45.jpg\n/kaggle/input/dataset/test/332.jpg\n/kaggle/input/dataset/test/11.jpg\n/kaggle/input/dataset/test/431.jpg\n/kaggle/input/dataset/test/224.jpg\n/kaggle/input/dataset/test/375.jpg\n/kaggle/input/dataset/test/421.jpg\n/kaggle/input/dataset/test/20.jpg\n/kaggle/input/dataset/test/152.jpg\n/kaggle/input/dataset/test/394.jpg\n/kaggle/input/dataset/test/456.jpg\n/kaggle/input/dataset/test/302.jpg\n/kaggle/input/dataset/test/410.jpg\n/kaggle/input/dataset/test/378.jpg\n/kaggle/input/dataset/test/380.jpg\n/kaggle/input/dataset/test/215.jpg\n/kaggle/input/dataset/test/487.jpg\n/kaggle/input/dataset/test/86.jpg\n/kaggle/input/dataset/test/460.jpg\n/kaggle/input/dataset/test/508.jpg\n/kaggle/input/dataset/test/416.jpg\n/kaggle/input/dataset/test/437.jpg\n/kaggle/input/dataset/test/316.jpg\n/kaggle/input/dataset/test/473.jpg\n/kaggle/input/dataset/test/210.jpg\n/kaggle/input/dataset/test/349.jpg\n/kaggle/input/dataset/test/269.jpg\n/kaggle/input/dataset/test/17.jpg\n/kaggle/input/dataset/test/457.jpg\n/kaggle/input/dataset/test/232.jpg\n/kaggle/input/dataset/test/285.jpg\n/kaggle/input/dataset/test/35.jpg\n/kaggle/input/dataset/test/171.jpg\n/kaggle/input/dataset/test/398.jpg\n/kaggle/input/dataset/test/484.jpg\n/kaggle/input/dataset/test/330.jpg\n/kaggle/input/dataset/test/23.jpg\n/kaggle/input/dataset/test/55.jpg\n/kaggle/input/dataset/test/157.jpg\n/kaggle/input/dataset/test/220.jpg\n/kaggle/input/dataset/test/373.jpg\n/kaggle/input/dataset/test/411.jpg\n/kaggle/input/dataset/test/520.jpg\n/kaggle/input/dataset/test/448.jpg\n/kaggle/input/dataset/test/57.jpg\n/kaggle/input/dataset/test/323.jpg\n/kaggle/input/dataset/test/363.jpg\n/kaggle/input/dataset/test/439.jpg\n/kaggle/input/dataset/test/386.jpg\n/kaggle/input/dataset/test/482.jpg\n/kaggle/input/dataset/test/505.jpg\n/kaggle/input/dataset/test/114.jpg\n/kaggle/input/dataset/test/440.jpg\n/kaggle/input/dataset/test/119.jpg\n/kaggle/input/dataset/test/301.jpg\n/kaggle/input/dataset/test/145.jpg\n/kaggle/input/dataset/test/385.jpg\n/kaggle/input/dataset/test/14.jpg\n/kaggle/input/dataset/test/28.jpg\n/kaggle/input/dataset/test/306.jpg\n/kaggle/input/dataset/test/467.jpg\n/kaggle/input/dataset/test/291.jpg\n/kaggle/input/dataset/test/189.jpg\n/kaggle/input/dataset/test/202.jpg\n/kaggle/input/dataset/test/498.jpg\n/kaggle/input/dataset/test/6.jpg\n/kaggle/input/dataset/test/194.jpg\n/kaggle/input/dataset/test/270.jpg\n/kaggle/input/dataset/test/200.jpg\n/kaggle/input/dataset/test/470.jpg\n/kaggle/input/dataset/test/41.jpg\n/kaggle/input/dataset/test/280.jpg\n/kaggle/input/dataset/test/256.jpg\n/kaggle/input/dataset/test/173.jpg\n/kaggle/input/dataset/test/80.jpg\n/kaggle/input/dataset/test/193.jpg\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\npath= '/kaggle/input/dataset/'\nk= '/kaggle/input/dataset/train.csv'\np ='/kaggle/input/dataset/test.csv'","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(k)\ntest=pd.read_csv(p)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5),test.head(5)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(     Image         target\n 0   96.jpg       manipuri\n 1  163.jpg  bharatanatyam\n 2  450.jpg         odissi\n 3  219.jpg      kathakali\n 4  455.jpg         odissi,\n      Image\n 0  508.jpg\n 1  246.jpg\n 2  473.jpg\n 3  485.jpg\n 4  128.jpg)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nfrom fastai import *\nfrom fastai.vision import *\nimport torch\nfrom fastai.callbacks.hooks import *","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path ='/kaggle/input/dataset/train/'\ntfms = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False,xtra_tfms=[cutout()])\ndata = (ImageList.from_csv(path, csv_name = '../train.csv')\n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=400)\n        .databunch(num_workers=0,bs=8))","execution_count":16,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] File /kaggle/input/DataSet/Train Images/../train.csv does not exist: '/kaggle/input/DataSet/Train Images/../train.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-d145148cabd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/DataSet/Train Images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip_vert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_zoom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_warp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_flip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtra_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m data = (ImageList.from_csv(path, csv_name = '../train.csv')\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0msplit_by_rand_pct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mlabel_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, csv_name, header, delimiter, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;34m\"Get the filenames in `path/csv_name` opened with `header`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/DataSet/Train Images/../train.csv does not exist: '/kaggle/input/DataSet/Train Images/../train.csv'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## to see the images in train with there labels\ndata.show_batch(rows=3, figsize=(8,10))","execution_count":14,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-b1fba89ebee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## to see the images in train with there labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mshow_batch\u001b[0;34m(self, rows, ds_type, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"Show a batch of data in `ds_type` on a few `rows`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_square_show\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mproc_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"Process batch `b` of `TensorImage`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(b, device)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"Recursively put `b` on `device`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mItemsList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/core.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/core.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfirst_el\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"Recursively put `b` on `device`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mItemsList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## print the target classes\nprint(data.classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\nresnext50_32x4d = models.resnext50_32x4d()\nwide_resnet50_2 = models.wide_resnet50_2()\nmnasnet = models.mnasnet1_0()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\nresnext50_32x4d = models.resnext50_32x4d(pretrained=True)\nwide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\nmnasnet = models.mnasnet1_0(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnext50_32x4d, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom fastai import *\nfrom fastai.vision import *\nfrom sklearn.model_selection import StratifiedKFold\nfrom pathlib import Path\nimport shutil\nfrom sklearn.metrics import f1_score, confusion_matrix\n\nnp.random.seed(1786)\nROOT = \"/tmp/data0125004\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef read_data(root):\n    train_df = pd.read_csv(k)\n    test_df = pd.read_csv(p)\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SaveBestModel(Recorder):\n    def __init__(self, learn,name='best_model'):\n        super().__init__(learn)\n        self.name = name\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_acc\n        \n    def save_when_acc(self, metrics):        \n        loss, acc = metrics[0], metrics[1]\n        if (self.best_acc is None) or (acc > self.best_acc) or (loss < self.best_loss):\n            self.best_acc = acc\n            self.best_loss = loss\n            self.learn.save(f'{self.name}')\n            print(\"Save the best acc {:.5f}\".format(self.best_acc))\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.learn.save(f'{self.name}')\n            print(\"Acc is eq,Save the lower loss {:.5f}\".format(self.best_loss))\n            \n    def on_epoch_end(self,last_metrics=MetricsList,**kwargs:Any):\n        self.save_method(last_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Path(ROOT).mkdir(exist_ok=True, parents=True)\nsrc1 = \"/kaggle/input/dataset/\"\nshutil.copytree(src1, ROOT)\n\n\nif __name__==\"__main__\":\n    train_df, test_df = read_data(ROOT)\n    print(train_df.shape, test_df.shape)\n    \n    cvlist = list(StratifiedKFold(16, random_state=12345786).split(train_df, train_df.target))\n    \n    tfms1 = get_transforms(max_zoom=1.5)\n    test_preds_all = []\n    val_preds_all = []\n    for i in range(1):\n        print(\"Starting fold {}\".format(i))\n        tr_idx, val_idx = cvlist[i]\n        print(tr_idx.shape, val_idx.shape)\n        src = (ImageList.from_df(train_df, path=ROOT, folder=\"train\").split_by_idxs(tr_idx, val_idx)\n                                                            .label_from_df())\n        data = ImageDataBunch.create_from_ll(src, ds_tfms=tfms1, size=224, bs=32, resize_method=3).normalize(imagenet_stats)\n        data.add_test(ImageList.from_df(test_df, path=ROOT, folder=\"test\"))\n        learn = cnn_learner(data, models.densenet161, metrics=accuracy, ps=0.5)\n        # learn.model[0].load_state_dict(torch.load(\"../input/save-body-weights-marvel/bestmodel_body.path\"))\n        cb = SaveBestModel(learn, name=\"bestmodel_{}\".format(i))\n        # learn.fit(1, callbacks=cb)\n        learn.fit_one_cycle(4)\n        learn.unfreeze()\n        learn.fit_one_cycle(10, max_lr=1e-4, callbacks=[cb])\n        learn.fit_one_cycle(10, max_lr=5e-5, callbacks=[cb])\n        learn.fit_one_cycle(10, max_lr=1e-5, callbacks=[cb])\n        learn.fit_one_cycle(10, max_lr=5e-6, callbacks=[cb])\n        learn.fit_one_cycle(1, max_lr=1e-6, callbacks=[cb])\n        learn.load(\"bestmodel_{}\".format(i))\n        val_preds, y = learn.TTA(ds_type=DatasetType.Valid)\n        val_preds = np.exp(val_preds.numpy())\n        print(\"F1 score for this fold \",f1_score(y.numpy(), np.argmax(val_preds,axis=1), average='weighted'))\n        test_preds = np.exp(learn.TTA(ds_type=DatasetType.Test)[0].numpy())\n        test_preds_all.append(test_preds)\n        val_preds_all.append(val_preds)\n        fname = \"bestmodel_{}.pth\".format(i)\n        src = str(Path(ROOT) / \"models\" / fname)\n        shutil.copy(src, fname)\n    test_preds_all = np.mean(test_preds_all, axis=0)\n    val_preds_all = np.concatenate(val_preds_all, axis=0)\n\n    np.save(\"test_preds.npy\", test_preds_all)\n    np.save(\"val_preds.npy\", val_preds_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = test_df[[\"Image\"]]\nsub[\"target\"] = np.argmax(test_preds, axis=1)\nsub.to_csv(\"dense00.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}